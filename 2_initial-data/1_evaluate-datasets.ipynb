{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c208962c-8132-4962-8995-d660d113ad96",
   "metadata": {},
   "source": [
    "# Evaluate Datasets\n",
    "Count how much data we have from each source, compare predictions and estimate runtimes. What I'll need to determine a suitable pipeline later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567928e0-7a2b-48a8-b5d8-3d830ee6ba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228eb755-f134-4b25-814c-67df90a84ff7",
   "metadata": {},
   "source": [
    "Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0bde05-223d-41d1-970c-7d8aa134e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_read = ['mdf-mos']  # Names of the molecule data sources\n",
    "config_names = ['xtb', 'mopac_pm7', 'cp2k_b3lyp_svp', 'cp2k_b3lyp_tzvpd', 'cp2k_wb97x_d3_tzvpd']  # Approaches, ordered by increasing runtime\n",
    "approx_names = ['vertical', 'acn-vertical', 'adiabatic', 'acn-adiabatic']  # Approximations for redox potential, increasing by runtime\n",
    "redox_properties = ['oxidation_potential', 'reduction_potential']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37959c-0492-4ca2-b348-784ae130136e",
   "metadata": {},
   "source": [
    "## Load in the datasets\n",
    "Load in the dataset and the time estimates for each step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68a0216-cb12-4030-b210-5cabe30cee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89aed961-fd49-412e-b0b9-6ae1f3e42a9e",
   "metadata": {},
   "source": [
    "Start by loading molecule records with the properties and identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e22d0b-81da-447f-85d2-d33fa93f7e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = set()\n",
    "recipes = set()\n",
    "for source in to_read:\n",
    "    with gzip.open(f'datasets/{source}.json.gz') as fp:\n",
    "        for line in tqdm(fp, desc=source):\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # Skip if there are no conformers, \n",
    "            #  which means no computations succeeded\n",
    "            if len(data['conformers']) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Start by storing the identity and source\n",
    "            record = defaultdict(float)\n",
    "            record.update({\n",
    "                'key': data['key'],\n",
    "                'source': source,\n",
    "                'smiles': data['identifier']['smiles'],\n",
    "                'n_atoms': int(data['conformers'][0]['xyz'].split(\"\\n\")[0])\n",
    "            })\n",
    "            \n",
    "            # Store the properties\n",
    "            for prop, values in data['properties'].items():\n",
    "                properties.add(prop)\n",
    "                for level, value in values.items():\n",
    "                    if abs(value) > 20 and 'potential' in prop:  # Some QM9 computations go off\n",
    "                        #print(f'Failure of {data[\"key\"]} for {prop}//{level}')\n",
    "                        continue\n",
    "                    recipe = f'{prop}.{level}'\n",
    "                    recipes.add(recipe)\n",
    "                    record[recipe] = value\n",
    "            \n",
    "            # Add to the total record list\n",
    "            records[record['key']] = record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377c7cd-c931-4eba-a4d6-4f66c0dbe2d2",
   "metadata": {},
   "source": [
    "Load in the runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c5222-5dae-415a-a02a-bfd34c67bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in to_read:\n",
    "    try:\n",
    "        fp = gzip.open(f'datasets/{source}-results.json.gz')\n",
    "        for line in tqdm(fp, desc=source):\n",
    "            data = json.loads(line)\n",
    "            \n",
    "            # Skip if unsuccessful, or if source does not not match\n",
    "            key = data[\"task_info\"][\"key\"]\n",
    "            if not data['success'] or key not in records:\n",
    "                continue\n",
    "            record = records[key]\n",
    "            if record['source'] != source:\n",
    "                continue\n",
    "                \n",
    "            # Update the times\n",
    "            prop = data[\"task_info\"][\"recipe\"]\n",
    "            level = data[\"task_info\"][\"level\"]\n",
    "            tag = f'runtime.{prop}.{level}'\n",
    "            record[tag] += data[\"time_running\"]\n",
    "            \n",
    "            # If the type is a neutral relaxation, add it the other potential\n",
    "            if data[\"method\"] == \"optimize_structure\" and level.endswith(\"vertical\"):\n",
    "                prop = \"oxidation_potential\" if prop == \"reduction_potential\" else \"reduction_potential\"\n",
    "                tag = f'runtime.{prop}.{level}'\n",
    "                record[tag] += data[\"time_running\"]\n",
    "    except EOFError:  # Thrown if gzip file is still being written\n",
    "        continue\n",
    "    finally:\n",
    "        fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85812358-0ea3-46df-8e94-797b6c0a8c68",
   "metadata": {},
   "source": [
    "Convert it to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7250e-3778-463b-b2e8-83ef2723ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = pd.DataFrame(records.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefca5f2-03e8-4b30-a3f8-a8d31bba45a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Loaded a dataset of {len(records)} molecules with {len(properties)} properties computed at a total of {len(recipes)} levels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50443326-75ec-4ec9-90ae-430afc575d81",
   "metadata": {},
   "source": [
    "CP2K tasks are checkpointed, so the runtimes are probably longer than reported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd5c8ee-461b-4e8c-bdc1-fe5624652c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90119f52-a0b6-4531-b2f2-672a0a07c75c",
   "metadata": {},
   "source": [
    "## Compute Cumulative Runtime\n",
    "Assume that we execute recipes by doing all approximations with the cheapest configuration before progressing to the next configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2155856-4596-4e7f-aa9c-311ce5fdef69",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_order = [\n",
    "    f'{c}-{a}'\n",
    "    for c in config_names\n",
    "    for a in approx_names\n",
    "]\n",
    "print(f'Generated {len(run_order)} recipes:')\n",
    "run_order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94409f75-937d-49e6-bc78-352530d9747c",
   "metadata": {},
   "source": [
    "Compute the cumulative runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b697e-d0df-40c5-8ab7-cb18377d54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for prop in redox_properties:\n",
    "    each_levels = [f'runtime.{prop}.{l}' for l in run_order]\n",
    "    total_levels = [f'cumulative.{prop}.{l}' for l in run_order]\n",
    "    \n",
    "    records[total_levels] = records[each_levels].cumsum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70d20ba-6ddf-4b09-beb1-0378bfc71a94",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- 12Sep23: I switched from 4 workers per node on 1, and also from temporary files on global filesystems to node-level shm. \n",
    "- 20Sep23: Use FIRE for relaxation first\n",
    "- 02Oct23: Switched from BFGSLineSearch to BFGS\n",
    "- 24Jan23: Increased NBUFFER and number of electronic steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fcd014-4f5b-4cd7-898d-754959a5d5bc",
   "metadata": {},
   "source": [
    "## Compute Error\n",
    "Compute the error at each level wrt to the top level of accuracy. We are going to use MAE after correcting for any offsets between the two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a32ba9d-b30e-4a1a-88ee-516a4c80d390",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Computing error relative to: {run_order[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b92fc84-73f8-456b-af9d-6f36eebf943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axxs = plt.subplots(len(redox_properties), len(run_order) - 1, figsize=(2.5 * (len(run_order) - 1), 5.), sharey='row', sharex='row')\n",
    "\n",
    "for prop, axs in zip(redox_properties, axxs):\n",
    "    target_col = f'{prop}.{run_order[-1]}'\n",
    "    if target_col not in records.columns:\n",
    "        print(f'No data for {target_col}')\n",
    "        continue\n",
    "    count = np.logical_not(records[target_col].isnull()).sum()\n",
    "    print(f'Found {count} records for {prop}')\n",
    "    for level, ax in zip(run_order, axs):\n",
    "        col = f'{prop}.{level}'\n",
    "        if col not in records.columns:\n",
    "            print(f'No data for {col}')\n",
    "            continue\n",
    "        \n",
    "        # Subtract off the average error\n",
    "        mae = (records[col] - records[target_col]).abs().mean()\n",
    "        mean_error = (records[col] - records[target_col]).mean()\n",
    "        mae_corrected = (records[col] - mean_error - records[target_col]).abs().mean()\n",
    "        print(f'Prop: {prop} - Level: {level} - MAE: {mae:.2f} - MAE,corrected: {mae_corrected:.2f}')\n",
    "        \n",
    "        ax.scatter(records[col] - mean_error, records[target_col], s=4, ec='none', alpha=0.7)\n",
    "        \n",
    "    # Format the axes\n",
    "    axs[0].set_ylabel(f'{prop} (V)\\n{config_names[-1]}\\n{approx_names[-1]}', fontsize=8)\n",
    "    \n",
    "# Add y=x\n",
    "for ax in axxs.flatten():\n",
    "    ax.set_xlim(ax.get_ylim())\n",
    "    ax.set_ylim(ax.get_ylim())\n",
    "    ax.plot(ax.get_xlim(), ax.get_xlim(), 'k--')\n",
    "    ax.set_xticklabels([])\n",
    "    \n",
    "# Add the level titles\n",
    "for ax, level in zip(axxs[0, :], run_order):\n",
    "    for name in config_names:\n",
    "        if level.startswith(name):\n",
    "            conf = name\n",
    "            appr = level[len(conf)+1:]\n",
    "    ax.set_title(f'{conf}\\n{appr}', fontsize=8)\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/pred-vs-actual-redox.png', dpi=320)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89f7f41-917c-411a-9b9d-2966b894d1d5",
   "metadata": {},
   "source": [
    "Create a Pareto plot which shows the cumulative runtime vs accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9a4e5-65c9-498a-a26a-62d75a4b8920",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(6.5, 2.), sharex=True, sharey=True)\n",
    "\n",
    "summary = []\n",
    "for prop, ax in zip(redox_properties, axs):\n",
    "    # Get the levels which were ran\n",
    "    levels = [f'{prop}.{l}' for l in run_order if f'{prop}.{l}' in records.columns]\n",
    "    print(f'Comparing {prop} to {levels[-1]}')\n",
    "    \n",
    "    # Compute the MAE without the offest\n",
    "    error_all = (records[levels].values - records[levels[-1]].values[:, None])\n",
    "    offset_all = np.nanmedian(error_all, axis=0)\n",
    "    mae_by_level = np.nanmedian(np.abs(error_all - offset_all), axis=0)\n",
    "    best_so_far = [min(mae_by_level[:i + 1]) for i in range(len(mae_by_level))]\n",
    "    is_best = np.isclose(mae_by_level, best_so_far)\n",
    "    \n",
    "    # Compute the runtime for complete computations\n",
    "    runtime_all = records[[f'cumulative.{l}' for l in levels]].values\n",
    "    runtime_all[np.isnan(error_all)] = np.nan\n",
    "    runtime_by_level = np.nanmedian(runtime_all, axis=0)\n",
    "    \n",
    "    ax.scatter(runtime_by_level, mae_by_level, \n",
    "               color=['seagreen' if i else 'lightsalmon' for i in is_best])\n",
    "    \n",
    "    summary.append(pd.DataFrame({\n",
    "        'property': [prop] * len(levels),\n",
    "        'level': [l[len(prop) + 1:] for l in levels],\n",
    "        'count': np.isfinite(error_all).sum(axis=0),\n",
    "        'runtime': runtime_by_level,\n",
    "        'improved': is_best,\n",
    "        'error': mae_by_level,\n",
    "    }))\n",
    "\n",
    "    # Prettify\n",
    "    ax.set_xlabel('Runtime (s)')\n",
    "    ax.set_title(prop, fontsize=10)\n",
    "    ax.set_xscale('log')\n",
    "\n",
    "axs[0].set_ylabel('MAE (V)')\n",
    "summary = pd.concat(summary)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/recipe-pareto-plot-redox.png', dpi=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec6a06e-20b9-4e76-b6d7-e140e9d8215e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "summary.to_csv('runtime-vs-performance-summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be6e67bc-d18f-4007-b4fa-61dc917bee38",
   "metadata": {},
   "source": [
    "Save a copy of the dataset with the columns in a reasonable order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df42147d-962f-499f-b50f-487defd43163",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_cols = sorted(records.columns, key=lambda x: (x.count(\".\"), x))\n",
    "print(f'Displaying columns: {\",\".join(sorted_cols[:6])},...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bca700-3b3c-45d4-96dc-7afeba711eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "records[sorted_cols].to_csv(f'datasets/{\"-\".join(to_read)}_consolidated.csv.gz', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979317b6-788c-4bf4-840a-d480f5f7fe71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
